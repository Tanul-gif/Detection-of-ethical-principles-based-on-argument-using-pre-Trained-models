{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QcMdqrPOmmYM",
        "outputId": "4bada428-47dd-4034-9939-20d22a956502"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import textblob\n",
        "textblob.download_corpora()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "rBxYSUx_nttK",
        "outputId": "e030c6f7-a6f6-4d38-f2a9-82d277d7ce14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "module 'textblob' has no attribute 'download_corpora'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-43a460906cde>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtextblob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtextblob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_corpora\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: module 'textblob' has no attribute 'download_corpora'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m textblob.download_corpora"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HSXF6cGunsFe",
        "outputId": "76b11689-2e80-41e9-85ae-9a732bd1f3bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n",
            "[nltk_data] Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n",
            "Finished.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "drWPsNhLmXs8",
        "outputId": "cf08aa2d-58f3-46cd-b358-448b5d8d9757"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 44652/44652 [00:07<00:00, 5711.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìç SVM (NRC Features) Evaluation\n",
            "Accuracy: 0.48605979173664765\n",
            "Macro F1-score: 0.0\n",
            "Macro Precision: 0.0\n",
            "Macro Recall: 0.0\n",
            "\n",
            "üìç Naive Bayes (NRC Features) Evaluation\n",
            "Accuracy: 0.46377785242414066\n",
            "Macro F1-score: 0.004159592529711375\n",
            "Macro Precision: 0.0034709924204859386\n",
            "Macro Recall: 0.005189028910303929\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# üì¶ Install required packages\n",
        "!pip install nrclex --quiet\n",
        "\n",
        "# üìö Imports\n",
        "import pandas as pd\n",
        "from nrclex import NRCLex\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.multioutput import MultiOutputClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "# üìÇ Load Data (upload these files to Colab)\n",
        "sentences = pd.read_csv(\"/content/drive/MyDrive/preprocessed_data.csv\")\n",
        "labels = pd.read_csv(\"/content/drive/MyDrive/training-english/labels.tsv\", sep=\"\\t\")\n",
        "\n",
        "# üîÅ Merge on 'Text-ID' and 'Sentence-ID'\n",
        "df = pd.merge(sentences, labels, on=[\"Text-ID\", \"Sentence-ID\"])\n",
        "df = df.dropna(subset=[\"cleaned_text\"])\n",
        "\n",
        "# üß† Emotion Categories (NRC-based)\n",
        "emotion_categories = ['anger', 'anticipation', 'disgust', 'fear', 'joy', 'sadness', 'surprise', 'trust', 'positive', 'negative']\n",
        "\n",
        "# üîç Extract NRC Emotion Features\n",
        "def extract_nrc_features(text):\n",
        "    emotion_obj = NRCLex(text)\n",
        "    scores = emotion_obj.affect_frequencies\n",
        "    return [scores.get(e, 0) for e in emotion_categories]\n",
        "# üß† Apply to all sentences\n",
        "tqdm.pandas()\n",
        "X_features = df[\"cleaned_text\"].progress_apply(extract_nrc_features)\n",
        "X = pd.DataFrame(X_features.tolist(), columns=emotion_categories)\n",
        "\n",
        "# üè∑Ô∏è Labels\n",
        "y = df.drop(columns=[\"Text-ID\", \"Sentence-ID\", \"Text\", \"cleaned_text\"])\n",
        "y = (y >= 0.5).astype(int)  # Binarize labels\n",
        "\n",
        "# üîÄ Train/Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# üîÅ Models\n",
        "svm = MultiOutputClassifier(LinearSVC())\n",
        "nb = MultiOutputClassifier(BernoulliNB())\n",
        "\n",
        "# üèãÔ∏è Train\n",
        "svm.fit(X_train, y_train)\n",
        "nb.fit(X_train, y_train)\n",
        "\n",
        "# üîé Predict\n",
        "svm_preds = svm.predict(X_test)\n",
        "nb_preds = nb.predict(X_test)\n",
        "\n",
        "# üìä Evaluation\n",
        "def evaluate_model(y_true, y_pred, model_name):\n",
        "    print(f\"\\nüìç {model_name} Evaluation\")\n",
        "    print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n",
        "    print(\"Macro F1-score:\", f1_score(y_true, y_pred, average=\"macro\", zero_division=0))\n",
        "    print(\"Macro Precision:\", precision_score(y_true, y_pred, average=\"macro\", zero_division=0))\n",
        "    print(\"Macro Recall:\", recall_score(y_true, y_pred, average=\"macro\", zero_division=0))\n",
        "\n",
        "# üßæ Show Results\n",
        "evaluate_model(y_test, svm_preds, \"SVM (NRC Features)\")\n",
        "evaluate_model(y_test, nb_preds, \"Naive Bayes (NRC Features)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##BERT EMBEDDINGS + NRC"
      ],
      "metadata": {
        "id": "Lfdah_Mio0ap"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# üì¶ Install required packages\n",
        "!pip install nrclex --quiet\n",
        "\n",
        "# üìö Imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from nrclex import NRCLex\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.multioutput import MultiOutputClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
        "from tqdm import tqdm\n",
        "\n",
        "# üìÇ Load files (upload these in Colab)\n",
        "sentences = pd.read_csv(\"/content/drive/MyDrive/preprocessed_data.csv\")\n",
        "labels = pd.read_csv(\"/content/drive/MyDrive/training-english/labels.tsv\", sep=\"\\t\")\n",
        "bert_embeddings = np.load(\"/content/drive/MyDrive/training-english/bert_embeddings.npy\")  # Shape should be (n_samples, 768)\n",
        "\n",
        "# üîÅ Merge data\n",
        "df = pd.merge(sentences, labels, on=[\"Text-ID\", \"Sentence-ID\"])\n",
        "df = df.dropna(subset=[\"cleaned_text\"])\n",
        "df = df.reset_index(drop=True)\n",
        "\n",
        "# ‚úÖ NRC Emotion Feature Extraction\n",
        "emotion_categories = ['anger', 'anticipation', 'disgust', 'fear', 'joy',\n",
        "                      'sadness', 'surprise', 'trust', 'positive', 'negative']\n",
        "\n",
        "def extract_nrc_features(text):\n",
        "    emotion_obj = NRCLex(text)\n",
        "    scores = emotion_obj.affect_frequencies\n",
        "    return [scores.get(e, 0) for e in emotion_categories]\n",
        "\n",
        "tqdm.pandas()\n",
        "nrc_features = df[\"cleaned_text\"].progress_apply(extract_nrc_features)\n",
        "nrc_matrix = np.array(nrc_features.tolist())\n",
        "\n",
        "# ‚úÖ Combine NRC + BERT features\n",
        "\n",
        "bert_embeddings = bert_embeddings[:nrc_matrix.shape[0]]\n",
        "combined_features = np.hstack((bert_embeddings, nrc_matrix))\n",
        "\n",
        "# ‚úÖ Prepare labels\n",
        "y = df.drop(columns=[\"Text-ID\", \"Sentence-ID\", \"Text\", \"cleaned_text\"])\n",
        "y_binary = (y >= 0.5).astype(int)\n",
        "\n",
        "# üîÄ Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(combined_features, y_binary, test_size=0.2, random_state=42)\n",
        "\n",
        "# üîÅ Models\n",
        "svm = MultiOutputClassifier(LinearSVC())\n",
        "nb = MultiOutputClassifier(BernoulliNB())\n",
        "\n",
        "# üèãÔ∏è Train\n",
        "svm.fit(X_train, y_train)\n",
        "nb.fit(X_train, y_train)\n",
        "\n",
        "# üîé Predict\n",
        "svm_preds = svm.predict(X_test)\n",
        "nb_preds = nb.predict(X_test)\n",
        "\n",
        "# üìä Evaluation\n",
        "def evaluate_model(y_true, y_pred, name):\n",
        "    print(f\"\\nüìç {name} Evaluation\")\n",
        "    print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n",
        "    print(\"Macro F1-score:\", f1_score(y_true, y_pred, average=\"macro\", zero_division=0))\n",
        "    print(\"Macro Precision:\", precision_score(y_true, y_pred, average=\"macro\", zero_division=0))\n",
        "    print(\"Macro Recall:\", recall_score(y_true, y_pred, average=\"macro\", zero_division=0))\n",
        "\n",
        "evaluate_model(y_test, svm_preds, \"SVM (BERT + NRC)\")\n",
        "evaluate_model(y_test, nb_preds, \"Naive Bayes (BERT + NRC)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5NTrpWRjoy0w",
        "outputId": "3b71af1b-8657-4b25-cde5-f1d2c1cce860"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 44652/44652 [00:13<00:00, 3426.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìç SVM (BERT + NRC) Evaluation\n",
            "Accuracy: 0.485052065838092\n",
            "Macro F1-score: 0.0\n",
            "Macro Precision: 0.0\n",
            "Macro Recall: 0.0\n",
            "\n",
            "üìç Naive Bayes (BERT + NRC) Evaluation\n",
            "Accuracy: 0.10323591982980629\n",
            "Macro F1-score: 0.050253609535145925\n",
            "Macro Precision: 0.030605058252982403\n",
            "Macro Recall: 0.20231624716387833\n"
          ]
        }
      ]
    }
  ]
}