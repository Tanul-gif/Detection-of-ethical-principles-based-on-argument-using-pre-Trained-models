{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IohYiEjhD3If"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQ_jNkm1HKxJ",
        "outputId": "446f6b43-01b4-4a24-b533-f68598fe6332"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abWzoF9ubdC3",
        "outputId": "8688f1f5-c21c-4842-916d-fbd27e31bd41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences_df = pd.read_csv('/content/drive/MyDrive/training-english/sentences.tsv',sep='\\t')\n",
        "labels_df = pd.read_csv('/content/drive/MyDrive/training-english/labels.tsv',sep='\\t')"
      ],
      "metadata": {
        "id": "0-DRjjU1djgU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "VwXsrmd2m_PY",
        "outputId": "40ec6a05-586b-4344-e6ba-2e1c8feae01c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  Text-ID  Sentence-ID                                               Text\n",
              "0  EN_001            1  Hispanic Voters Are Losing Faith In The Democr...\n",
              "1  EN_001            2  The support of Hispanic voters at the midterms...\n",
              "2  EN_001            3  U.S. President Joe Biden speaks to employees a...\n",
              "3  EN_001            4  (Julie Bennett/Getty Images) According to a Qu...\n",
              "4  EN_001            5  This marks the lowest approval rating of any d..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-06e223f1-dd0a-4e68-bda6-6a570d28cc22\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text-ID</th>\n",
              "      <th>Sentence-ID</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>EN_001</td>\n",
              "      <td>1</td>\n",
              "      <td>Hispanic Voters Are Losing Faith In The Democr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>EN_001</td>\n",
              "      <td>2</td>\n",
              "      <td>The support of Hispanic voters at the midterms...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>EN_001</td>\n",
              "      <td>3</td>\n",
              "      <td>U.S. President Joe Biden speaks to employees a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>EN_001</td>\n",
              "      <td>4</td>\n",
              "      <td>(Julie Bennett/Getty Images) According to a Qu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>EN_001</td>\n",
              "      <td>5</td>\n",
              "      <td>This marks the lowest approval rating of any d...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-06e223f1-dd0a-4e68-bda6-6a570d28cc22')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-06e223f1-dd0a-4e68-bda6-6a570d28cc22 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-06e223f1-dd0a-4e68-bda6-6a570d28cc22');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1fe5a608-20ee-46b1-8e96-e0cdd014e38e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1fe5a608-20ee-46b1-8e96-e0cdd014e38e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1fe5a608-20ee-46b1-8e96-e0cdd014e38e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "sentences_df",
              "summary": "{\n  \"name\": \"sentences_df\",\n  \"rows\": 44758,\n  \"fields\": [\n    {\n      \"column\": \"Text-ID\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1603,\n        \"samples\": [\n          \"DE_276\",\n          \"IT_164\",\n          \"EN_280\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sentence-ID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 11,\n        \"min\": 1,\n        \"max\": 82,\n        \"num_unique_values\": 82,\n        \"samples\": [\n          31,\n          1,\n          23\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 44495,\n        \"samples\": [\n          \"Flint\\u2019s water became tainted with lead after city managers appointed by Snyder began using the Flint River in 2014 to save money while a new pipeline to Lake Huron was built.\",\n          \"Watch the live broadcast.\",\n          \"Our ideas, he adds, -are solid, grounded, transparent, If policy actors converge, we recognize that.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels_df.head()"
      ],
      "metadata": {
        "id": "2BtI2WERFBmy",
        "outputId": "a58c607a-d52b-412c-dfa4-5116100efd0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  Text-ID  Sentence-ID  Self-direction: thought attained  \\\n",
              "0  BG_002            1                               0.0   \n",
              "1  BG_002            2                               0.0   \n",
              "2  BG_002            3                               0.0   \n",
              "3  BG_002            4                               0.0   \n",
              "4  BG_002            5                               0.0   \n",
              "\n",
              "   Self-direction: thought constrained  Self-direction: action attained  \\\n",
              "0                                  0.0                              0.0   \n",
              "1                                  0.0                              0.0   \n",
              "2                                  0.0                              0.0   \n",
              "3                                  0.0                              0.0   \n",
              "4                                  0.0                              0.0   \n",
              "\n",
              "   Self-direction: action constrained  Stimulation attained  \\\n",
              "0                                 0.0                   0.0   \n",
              "1                                 0.0                   0.0   \n",
              "2                                 0.0                   0.0   \n",
              "3                                 0.0                   0.0   \n",
              "4                                 0.0                   0.0   \n",
              "\n",
              "   Stimulation constrained  Hedonism attained  Hedonism constrained  ...  \\\n",
              "0                      0.0                0.0                   0.0  ...   \n",
              "1                      0.0                0.0                   0.0  ...   \n",
              "2                      0.0                1.0                   0.0  ...   \n",
              "3                      0.0                0.0                   0.0  ...   \n",
              "4                      0.0                0.0                   0.0  ...   \n",
              "\n",
              "   Benevolence: caring attained  Benevolence: caring constrained  \\\n",
              "0                           0.0                              0.0   \n",
              "1                           0.0                              0.0   \n",
              "2                           0.0                              0.0   \n",
              "3                           0.0                              0.0   \n",
              "4                           0.0                              0.0   \n",
              "\n",
              "   Benevolence: dependability attained  \\\n",
              "0                                  0.0   \n",
              "1                                  0.0   \n",
              "2                                  0.0   \n",
              "3                                  0.0   \n",
              "4                                  0.0   \n",
              "\n",
              "   Benevolence: dependability constrained  Universalism: concern attained  \\\n",
              "0                                     0.0                             0.0   \n",
              "1                                     0.0                             0.0   \n",
              "2                                     0.0                             0.0   \n",
              "3                                     0.0                             0.0   \n",
              "4                                     0.0                             0.0   \n",
              "\n",
              "   Universalism: concern constrained  Universalism: nature attained  \\\n",
              "0                                0.0                            0.0   \n",
              "1                                0.0                            0.0   \n",
              "2                                0.0                            0.0   \n",
              "3                                0.0                            0.0   \n",
              "4                                0.0                            0.0   \n",
              "\n",
              "   Universalism: nature constrained  Universalism: tolerance attained  \\\n",
              "0                               0.0                               0.0   \n",
              "1                               0.0                               0.0   \n",
              "2                               0.0                               0.0   \n",
              "3                               0.0                               0.0   \n",
              "4                               0.0                               0.0   \n",
              "\n",
              "   Universalism: tolerance constrained  \n",
              "0                                  0.0  \n",
              "1                                  0.0  \n",
              "2                                  0.0  \n",
              "3                                  0.0  \n",
              "4                                  0.0  \n",
              "\n",
              "[5 rows x 40 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-04441e59-050c-4c2b-9ce1-acda66b0de96\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text-ID</th>\n",
              "      <th>Sentence-ID</th>\n",
              "      <th>Self-direction: thought attained</th>\n",
              "      <th>Self-direction: thought constrained</th>\n",
              "      <th>Self-direction: action attained</th>\n",
              "      <th>Self-direction: action constrained</th>\n",
              "      <th>Stimulation attained</th>\n",
              "      <th>Stimulation constrained</th>\n",
              "      <th>Hedonism attained</th>\n",
              "      <th>Hedonism constrained</th>\n",
              "      <th>...</th>\n",
              "      <th>Benevolence: caring attained</th>\n",
              "      <th>Benevolence: caring constrained</th>\n",
              "      <th>Benevolence: dependability attained</th>\n",
              "      <th>Benevolence: dependability constrained</th>\n",
              "      <th>Universalism: concern attained</th>\n",
              "      <th>Universalism: concern constrained</th>\n",
              "      <th>Universalism: nature attained</th>\n",
              "      <th>Universalism: nature constrained</th>\n",
              "      <th>Universalism: tolerance attained</th>\n",
              "      <th>Universalism: tolerance constrained</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>BG_002</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>BG_002</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>BG_002</td>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>BG_002</td>\n",
              "      <td>4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>BG_002</td>\n",
              "      <td>5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 40 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-04441e59-050c-4c2b-9ce1-acda66b0de96')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-04441e59-050c-4c2b-9ce1-acda66b0de96 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-04441e59-050c-4c2b-9ce1-acda66b0de96');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c7b690f4-e916-41e9-9cc9-7862a798ff3a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c7b690f4-e916-41e9-9cc9-7862a798ff3a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c7b690f4-e916-41e9-9cc9-7862a798ff3a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "labels_df"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the sentences.tsv file\n",
        "# sentences_path = '/mnt/data/sentences.tsv'\n",
        "# # Load the file with appropriate column names\n",
        "# sentences_df = pd.read_csv(sentences_path, sep='\\t', names=['Text-ID', 'Sentence-ID', 'Text'])\n",
        "\n",
        "# Ensure that Sentence-ID is treated as a string (if needed)\n",
        "sentences_df['Sentence-ID'] = sentences_df['Sentence-ID'].astype(str)\n",
        "\n",
        "# Extract the text with the specified Text-ID and Sentence-ID\n",
        "text_extracted = sentences_df[\n",
        "    (sentences_df['Text-ID'] == 'BG_002') & (sentences_df['Sentence-ID'] == '3')]['Text'].values\n",
        "\n",
        "# Display the extracted text\n",
        "print(text_extracted)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j3fEYdep4iZ9",
        "outputId": "85a8eaa7-ce50-4212-a864-b87c1848b4cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['MORE BUNGALOWS AT LOWER PRICES The avalanche of revelations about how prominent GERB representatives in the government and parliament bought luxury apartments at low prices did not touch the tax authorities at all, but instead they tightened the noose around the president of the Supreme Court of Cassation (SCC), Lozan Panov.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sentences_df)\n",
        "print(labels_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UL_YTrILdn9-",
        "outputId": "4e3baf1a-6786-4f0a-eec4-9e71cf712f86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        Text-ID  Sentence-ID  \\\n",
            "0        EN_001            1   \n",
            "1        EN_001            2   \n",
            "2        EN_001            3   \n",
            "3        EN_001            4   \n",
            "4        EN_001            5   \n",
            "...         ...          ...   \n",
            "44753  TR_M_022           12   \n",
            "44754  TR_M_022           13   \n",
            "44755  TR_M_022           14   \n",
            "44756  TR_M_022           15   \n",
            "44757  TR_M_022           16   \n",
            "\n",
            "                                                    Text  \n",
            "0      Hispanic Voters Are Losing Faith In The Democr...  \n",
            "1      The support of Hispanic voters at the midterms...  \n",
            "2      U.S. President Joe Biden speaks to employees a...  \n",
            "3      (Julie Bennett/Getty Images) According to a Qu...  \n",
            "4      This marks the lowest approval rating of any d...  \n",
            "...                                                  ...  \n",
            "44753  The rent economy, which provides easy profits ...  \n",
            "44754  The tax base will be broadened, the tax burden...  \n",
            "44755  Supportive arrangements will be made to increa...  \n",
            "44756  In order to lift out of poverty those who are ...  \n",
            "44757  Basic needs, education, health and social serv...  \n",
            "\n",
            "[44758 rows x 3 columns]\n",
            "        Text-ID  Sentence-ID  Self-direction: thought attained  \\\n",
            "0        BG_002            1                               0.0   \n",
            "1        BG_002            2                               0.0   \n",
            "2        BG_002            3                               0.0   \n",
            "3        BG_002            4                               0.0   \n",
            "4        BG_002            5                               0.0   \n",
            "...         ...          ...                               ...   \n",
            "44753  TR_M_022           12                               0.0   \n",
            "44754  TR_M_022           13                               0.0   \n",
            "44755  TR_M_022           14                               0.0   \n",
            "44756  TR_M_022           15                               0.0   \n",
            "44757  TR_M_022           16                               0.0   \n",
            "\n",
            "       Self-direction: thought constrained  Self-direction: action attained  \\\n",
            "0                                      0.0                              0.0   \n",
            "1                                      0.0                              0.0   \n",
            "2                                      0.0                              0.0   \n",
            "3                                      0.0                              0.0   \n",
            "4                                      0.0                              0.0   \n",
            "...                                    ...                              ...   \n",
            "44753                                  0.0                              0.0   \n",
            "44754                                  0.0                              0.0   \n",
            "44755                                  0.0                              0.0   \n",
            "44756                                  0.0                              1.0   \n",
            "44757                                  0.0                              0.0   \n",
            "\n",
            "       Self-direction: action constrained  Stimulation attained  \\\n",
            "0                                     0.0                   0.0   \n",
            "1                                     0.0                   0.0   \n",
            "2                                     0.0                   0.0   \n",
            "3                                     0.0                   0.0   \n",
            "4                                     0.0                   0.0   \n",
            "...                                   ...                   ...   \n",
            "44753                                 0.0                   0.5   \n",
            "44754                                 0.0                   0.0   \n",
            "44755                                 0.0                   0.0   \n",
            "44756                                 0.0                   0.0   \n",
            "44757                                 0.0                   0.0   \n",
            "\n",
            "       Stimulation constrained  Hedonism attained  Hedonism constrained  ...  \\\n",
            "0                          0.0                0.0                   0.0  ...   \n",
            "1                          0.0                0.0                   0.0  ...   \n",
            "2                          0.0                1.0                   0.0  ...   \n",
            "3                          0.0                0.0                   0.0  ...   \n",
            "4                          0.0                0.0                   0.0  ...   \n",
            "...                        ...                ...                   ...  ...   \n",
            "44753                      0.5                0.0                   0.0  ...   \n",
            "44754                      0.0                0.0                   0.0  ...   \n",
            "44755                      0.0                0.0                   0.0  ...   \n",
            "44756                      0.0                0.0                   0.0  ...   \n",
            "44757                      0.0                0.0                   0.0  ...   \n",
            "\n",
            "       Benevolence: caring attained  Benevolence: caring constrained  \\\n",
            "0                               0.0                              0.0   \n",
            "1                               0.0                              0.0   \n",
            "2                               0.0                              0.0   \n",
            "3                               0.0                              0.0   \n",
            "4                               0.0                              0.0   \n",
            "...                             ...                              ...   \n",
            "44753                           0.0                              0.0   \n",
            "44754                           1.0                              0.0   \n",
            "44755                           0.0                              0.0   \n",
            "44756                           1.0                              0.0   \n",
            "44757                           1.0                              0.0   \n",
            "\n",
            "       Benevolence: dependability attained  \\\n",
            "0                                      0.0   \n",
            "1                                      0.0   \n",
            "2                                      0.0   \n",
            "3                                      0.0   \n",
            "4                                      0.0   \n",
            "...                                    ...   \n",
            "44753                                  0.0   \n",
            "44754                                  0.0   \n",
            "44755                                  0.0   \n",
            "44756                                  0.0   \n",
            "44757                                  0.0   \n",
            "\n",
            "       Benevolence: dependability constrained  Universalism: concern attained  \\\n",
            "0                                         0.0                             0.0   \n",
            "1                                         0.0                             0.0   \n",
            "2                                         0.0                             0.0   \n",
            "3                                         0.0                             0.0   \n",
            "4                                         0.0                             0.0   \n",
            "...                                       ...                             ...   \n",
            "44753                                     0.0                             0.0   \n",
            "44754                                     0.0                             0.0   \n",
            "44755                                     0.0                             0.0   \n",
            "44756                                     0.0                             0.0   \n",
            "44757                                     0.0                             0.0   \n",
            "\n",
            "       Universalism: concern constrained  Universalism: nature attained  \\\n",
            "0                                    0.0                            0.0   \n",
            "1                                    0.0                            0.0   \n",
            "2                                    0.0                            0.0   \n",
            "3                                    0.0                            0.0   \n",
            "4                                    0.0                            0.0   \n",
            "...                                  ...                            ...   \n",
            "44753                                0.0                            0.0   \n",
            "44754                                0.0                            0.0   \n",
            "44755                                0.0                            0.0   \n",
            "44756                                0.0                            0.0   \n",
            "44757                                0.0                            0.0   \n",
            "\n",
            "       Universalism: nature constrained  Universalism: tolerance attained  \\\n",
            "0                                   0.0                               0.0   \n",
            "1                                   0.0                               0.0   \n",
            "2                                   0.0                               0.0   \n",
            "3                                   0.0                               0.0   \n",
            "4                                   0.0                               0.0   \n",
            "...                                 ...                               ...   \n",
            "44753                               0.0                               0.0   \n",
            "44754                               0.0                               0.0   \n",
            "44755                               0.0                               0.0   \n",
            "44756                               0.0                               0.0   \n",
            "44757                               0.0                               0.0   \n",
            "\n",
            "       Universalism: tolerance constrained  \n",
            "0                                      0.0  \n",
            "1                                      0.0  \n",
            "2                                      0.0  \n",
            "3                                      0.0  \n",
            "4                                      0.0  \n",
            "...                                    ...  \n",
            "44753                                  0.0  \n",
            "44754                                  0.0  \n",
            "44755                                  0.0  \n",
            "44756                                  0.0  \n",
            "44757                                  0.0  \n",
            "\n",
            "[44758 rows x 40 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the embeddings\n",
        "embeddings = np.load('/content/drive/MyDrive/bert_embeddings.npy')\n",
        "\n",
        "# Load the labels\n",
        "data = pd.read_csv('/content/drive/MyDrive/training-english/labels.tsv')\n",
        "\n",
        "# Verify the data shapes\n",
        "print(\"Embeddings shape:\", embeddings.shape)\n",
        "print(\"Data preview:\\n\", data.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mQh9UPP4c4yU",
        "outputId": "3b59dd8b-ece0-446b-96e1-1f940af66f6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embeddings shape: (44758, 768)\n",
            "Data preview:\n",
            "   Text-ID\\tSentence-ID\\tSelf-direction: thought attained\\tSelf-direction: thought constrained\\tSelf-direction: action attained\\tSelf-direction: action constrained\\tStimulation attained\\tStimulation constrained\\tHedonism attained\\tHedonism constrained\\tAchievement attained\\tAchievement constrained\\tPower: dominance attained\\tPower: dominance constrained\\tPower: resources attained\\tPower: resources constrained\\tFace attained\\tFace constrained\\tSecurity: personal attained\\tSecurity: personal constrained\\tSecurity: societal attained\\tSecurity: societal constrained\\tTradition attained\\tTradition constrained\\tConformity: rules attained\\tConformity: rules constrained\\tConformity: interpersonal attained\\tConformity: interpersonal constrained\\tHumility attained\\tHumility constrained\\tBenevolence: caring attained\\tBenevolence: caring constrained\\tBenevolence: dependability attained\\tBenevolence: dependability constrained\\tUniversalism: concern attained\\tUniversalism: concern constrained\\tUniversalism: nature attained\\tUniversalism: nature constrained\\tUniversalism: tolerance attained\\tUniversalism: tolerance constrained\n",
            "0  BG_002\\t1\\t0.0\\t0.0\\t0.0\\t0.0\\t0.0\\t0.0\\t0.0\\t...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
            "1  BG_002\\t2\\t0.0\\t0.0\\t0.0\\t0.0\\t0.0\\t0.0\\t0.0\\t...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
            "2  BG_002\\t3\\t0.0\\t0.0\\t0.0\\t0.0\\t0.0\\t0.0\\t1.0\\t...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
            "3  BG_002\\t4\\t0.0\\t0.0\\t0.0\\t0.0\\t0.0\\t0.0\\t0.0\\t...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
            "4  BG_002\\t5\\t0.0\\t0.0\\t0.0\\t0.0\\t0.0\\t0.0\\t0.0\\t...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assuming `data` has a column named 'label' that holds the target labels\n",
        "label = labels_df.columns[2:]\n",
        "labels = data['label'].values\n",
        "\n",
        "# Split the data (80% train, 10% validation, 10% test)\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(embeddings, labels, test_size=0.2, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "# Check shapes of the splits\n",
        "print(\"Training set:\", X_train.shape, y_train.shape)\n",
        "print(\"Validation set:\", X_val.shape, y_val.shape)\n",
        "print(\"Test set:\", X_test.shape, y_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "id": "PNjiUu_Dbl1Z",
        "outputId": "377253db-606c-49c9-fb34-9e30f5e37025"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'label'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3805\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3806\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'label'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-9ef06ec7042b>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Assuming `data` has a column named 'label' that holds the target labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Split the data (80% train, 10% validation, 10% test)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4102\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4104\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3810\u001b[0m             ):\n\u001b[1;32m   3811\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3814\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'label'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "\n",
        "# Load BERT embeddings\n",
        "# Replace 'path/to/embeddings.npy' with the actual path to your embeddings file\n",
        "embeddings = np.load('/content/drive/MyDrive/bert_embeddings.npy')\n",
        "\n",
        "# Load labels\n",
        "# Replace 'path/to/labels.csv' with the actual path to your labels file\n",
        "data = pd.read_csv('/content/drive/MyDrive/training-english/labels.tsv', sep='\\t')\n",
        "\n",
        "# Check the first few rows and columns to understand the structure\n",
        "print(data.columns)  # Check the column names\n",
        "print(data.head())   # Inspect the first few rows\n",
        "\n",
        "# Extract the label columns (assuming labels start from the 3rd column, adjust as needed)\n",
        "label_columns = data.columns[2:]  # Assuming labels start from the 3rd column\n",
        "\n",
        "# Convert multi-labels into a binary format (1 or 0)\n",
        "# If a value is present, it will be 1, otherwise 0\n",
        "labels = data[label_columns].values\n",
        "\n",
        "# Split the data: 80% for training, 10% for validation, 10% for testing\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(\n",
        "    embeddings, labels, test_size=0.2, random_state=42\n",
        ")\n",
        "X_val, X_test, y_val, y_test = train_test_split(\n",
        "    X_temp, y_temp, test_size=0.5, random_state=42\n",
        ")\n",
        "\n",
        "# Check shapes of the splits\n",
        "print(\"Training set:\", X_train.shape, y_train.shape)\n",
        "print(\"Validation set:\", X_val.shape, y_val.shape)\n",
        "print(\"Test set:\", X_test.shape, y_test.shape)\n"
      ],
      "metadata": {
        "id": "bzxH6ldxdND1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74f6e981-f21e-4e19-da3a-9435f5213555"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Text-ID', 'Sentence-ID', 'Self-direction: thought attained',\n",
            "       'Self-direction: thought constrained',\n",
            "       'Self-direction: action attained', 'Self-direction: action constrained',\n",
            "       'Stimulation attained', 'Stimulation constrained', 'Hedonism attained',\n",
            "       'Hedonism constrained', 'Achievement attained',\n",
            "       'Achievement constrained', 'Power: dominance attained',\n",
            "       'Power: dominance constrained', 'Power: resources attained',\n",
            "       'Power: resources constrained', 'Face attained', 'Face constrained',\n",
            "       'Security: personal attained', 'Security: personal constrained',\n",
            "       'Security: societal attained', 'Security: societal constrained',\n",
            "       'Tradition attained', 'Tradition constrained',\n",
            "       'Conformity: rules attained', 'Conformity: rules constrained',\n",
            "       'Conformity: interpersonal attained',\n",
            "       'Conformity: interpersonal constrained', 'Humility attained',\n",
            "       'Humility constrained', 'Benevolence: caring attained',\n",
            "       'Benevolence: caring constrained',\n",
            "       'Benevolence: dependability attained',\n",
            "       'Benevolence: dependability constrained',\n",
            "       'Universalism: concern attained', 'Universalism: concern constrained',\n",
            "       'Universalism: nature attained', 'Universalism: nature constrained',\n",
            "       'Universalism: tolerance attained',\n",
            "       'Universalism: tolerance constrained'],\n",
            "      dtype='object')\n",
            "  Text-ID  Sentence-ID  Self-direction: thought attained  \\\n",
            "0  BG_002            1                               0.0   \n",
            "1  BG_002            2                               0.0   \n",
            "2  BG_002            3                               0.0   \n",
            "3  BG_002            4                               0.0   \n",
            "4  BG_002            5                               0.0   \n",
            "\n",
            "   Self-direction: thought constrained  Self-direction: action attained  \\\n",
            "0                                  0.0                              0.0   \n",
            "1                                  0.0                              0.0   \n",
            "2                                  0.0                              0.0   \n",
            "3                                  0.0                              0.0   \n",
            "4                                  0.0                              0.0   \n",
            "\n",
            "   Self-direction: action constrained  Stimulation attained  \\\n",
            "0                                 0.0                   0.0   \n",
            "1                                 0.0                   0.0   \n",
            "2                                 0.0                   0.0   \n",
            "3                                 0.0                   0.0   \n",
            "4                                 0.0                   0.0   \n",
            "\n",
            "   Stimulation constrained  Hedonism attained  Hedonism constrained  ...  \\\n",
            "0                      0.0                0.0                   0.0  ...   \n",
            "1                      0.0                0.0                   0.0  ...   \n",
            "2                      0.0                1.0                   0.0  ...   \n",
            "3                      0.0                0.0                   0.0  ...   \n",
            "4                      0.0                0.0                   0.0  ...   \n",
            "\n",
            "   Benevolence: caring attained  Benevolence: caring constrained  \\\n",
            "0                           0.0                              0.0   \n",
            "1                           0.0                              0.0   \n",
            "2                           0.0                              0.0   \n",
            "3                           0.0                              0.0   \n",
            "4                           0.0                              0.0   \n",
            "\n",
            "   Benevolence: dependability attained  \\\n",
            "0                                  0.0   \n",
            "1                                  0.0   \n",
            "2                                  0.0   \n",
            "3                                  0.0   \n",
            "4                                  0.0   \n",
            "\n",
            "   Benevolence: dependability constrained  Universalism: concern attained  \\\n",
            "0                                     0.0                             0.0   \n",
            "1                                     0.0                             0.0   \n",
            "2                                     0.0                             0.0   \n",
            "3                                     0.0                             0.0   \n",
            "4                                     0.0                             0.0   \n",
            "\n",
            "   Universalism: concern constrained  Universalism: nature attained  \\\n",
            "0                                0.0                            0.0   \n",
            "1                                0.0                            0.0   \n",
            "2                                0.0                            0.0   \n",
            "3                                0.0                            0.0   \n",
            "4                                0.0                            0.0   \n",
            "\n",
            "   Universalism: nature constrained  Universalism: tolerance attained  \\\n",
            "0                               0.0                               0.0   \n",
            "1                               0.0                               0.0   \n",
            "2                               0.0                               0.0   \n",
            "3                               0.0                               0.0   \n",
            "4                               0.0                               0.0   \n",
            "\n",
            "   Universalism: tolerance constrained  \n",
            "0                                  0.0  \n",
            "1                                  0.0  \n",
            "2                                  0.0  \n",
            "3                                  0.0  \n",
            "4                                  0.0  \n",
            "\n",
            "[5 rows x 40 columns]\n",
            "Training set: (35806, 768) (35806, 38)\n",
            "Validation set: (4476, 768) (4476, 38)\n",
            "Test set: (4476, 768) (4476, 38)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "BERT-BASE-UNCASED model transformer"
      ],
      "metadata": {
        "id": "IYdMOZRCG9Jp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
        "\n",
        "# Load sentence and label data\n",
        "sentences_df = pd.read_csv('/content/drive/MyDrive/training-english/sentences.tsv', sep='\\t')\n",
        "labels_df = pd.read_csv('/content/drive/MyDrive/training-english/labels.tsv', sep='\\t')\n",
        "\n",
        "# Load precomputed BERT embeddings (assuming they are in a file like embeddings.npy or similar)\n",
        "bert_embeddings = np.load('/content/drive/MyDrive/bert_embeddings.npy')  # Change the path accordingly\n",
        "\n",
        "# Preprocessing: Merging data and selecting the dominant label\n",
        "label_columns = labels_df.columns[2:]  # Exclude 'Text-ID' and 'Sentence-ID'\n",
        "labels_df['dominant_label'] = labels_df[label_columns].idxmax(axis=1)\n",
        "# Convert dominant labels to numerical categories\n",
        "labels_df['dominant_label'] = labels_df['dominant_label'].astype('category').cat.codes\n",
        "\n",
        "# Merge text and labels data\n",
        "merged_df = sentences_df.merge(labels_df[['Text-ID', 'Sentence-ID', 'dominant_label']], on=['Text-ID', 'Sentence-ID'])\n",
        "labels = merged_df['dominant_label'].values\n",
        "\n",
        "# Split data into training and validation sets\n",
        "train_embeddings, val_embeddings, train_labels, val_labels = train_test_split(bert_embeddings, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert to torch tensors\n",
        "train_embeddings = torch.tensor(train_embeddings)\n",
        "val_embeddings = torch.tensor(val_embeddings)\n",
        "train_labels = torch.tensor(train_labels)\n",
        "val_labels = torch.tensor(val_labels)\n",
        "\n",
        "# Define the classifier (e.g., a logistic regression model, or you could use a neural network)\n",
        "classifier = LogisticRegression(max_iter=1000)\n",
        "\n",
        "# Fit the classifier on the training data\n",
        "classifier.fit(train_embeddings.numpy(), train_labels.numpy())\n",
        "\n",
        "# Evaluate the classifier on the validation data\n",
        "val_preds = classifier.predict(val_embeddings.numpy())\n",
        "accuracy = accuracy_score(val_labels.numpy(), val_preds)\n",
        "f1 = f1_score(val_labels.numpy(), val_preds, average='weighted')\n",
        "\n",
        "print(f\"Validation Accuracy: {accuracy}\")\n",
        "print(f\"Validation F1 Score: {f1}\")\n",
        "\n",
        "# Save the trained model\n",
        "joblib.dump(model, 'emotion_detection.joblib')\n",
        "\n",
        "print(\"Model saved as 'emotion_detection.joblib'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42H6m0B1G8Wg",
        "outputId": "9b3a1dac-0387-4553-87e9-35b804f731b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.5087131367292225\n",
            "Validation F1 Score: 0.4465409475200725\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
        "\n",
        "# Load sentence and label data\n",
        "sentences_df = pd.read_csv('/content/drive/MyDrive/training-english/sentences.tsv', sep='\\t')\n",
        "labels_df = pd.read_csv('/content/drive/MyDrive/training-english/labels.tsv', sep='\\t')\n",
        "\n",
        "# Load precomputed BERT embeddings (assuming they are in a file like embeddings.npy or similar)\n",
        "bert_embeddings = np.load('/content/drive/MyDrive/bert_embeddings.npy')  # Change the path accordingly\n",
        "\n",
        "# Preprocessing: Merging data and selecting the dominant label\n",
        "label_columns = labels_df.columns[2:]  # Exclude 'Text-ID' and 'Sentence-ID'\n",
        "labels_df['dominant_label'] = labels_df[label_columns].idxmax(axis=1)\n",
        "# Convert dominant labels to numerical categories\n",
        "labels_df['dominant_label'] = labels_df['dominant_label'].astype('category').cat.codes\n",
        "\n",
        "# Merge text and labels data\n",
        "merged_df = sentences_df.merge(labels_df[['Text-ID', 'Sentence-ID', 'dominant_label']], on=['Text-ID', 'Sentence-ID'])\n",
        "labels = merged_df['dominant_label'].values\n",
        "\n",
        "# Split data into training and validation sets\n",
        "train_embeddings, val_embeddings, train_labels, val_labels = train_test_split(bert_embeddings, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert to torch tensors\n",
        "train_embeddings = torch.tensor(train_embeddings)\n",
        "val_embeddings = torch.tensor(val_embeddings)\n",
        "train_labels = torch.tensor(train_labels)\n",
        "val_labels = torch.tensor(val_labels)\n",
        "\n",
        "# Define the classifier (e.g., a logistic regression model)\n",
        "classifier = LogisticRegression(max_iter=1000)\n",
        "\n",
        "# Fit the classifier on the training data\n",
        "classifier.fit(train_embeddings.numpy(), train_labels.numpy())\n",
        "\n",
        "# Evaluate the classifier on the validation data\n",
        "val_preds = classifier.predict(val_embeddings.numpy())\n",
        "\n",
        "# Accuracy score\n",
        "accuracy = accuracy_score(val_labels.numpy(), val_preds)\n",
        "\n",
        "# F1-score\n",
        "f1 = f1_score(val_labels.numpy(), val_preds, average='weighted')\n",
        "\n",
        "# Classification report for detailed performance metrics (precision, recall, f1-score, support)\n",
        "report = classification_report(val_labels.numpy(), val_preds, target_names=[str(i) for i in range(len(np.unique(labels)))])\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"F1 Score: {f1}\")\n",
        "# print(\"Classification Report:\\n\", report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OUJB1P8jcu6n",
        "outputId": "0a461f45-e299-4273-f6e8-b9216f99d1ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5087131367292225\n",
            "F1 Score: 0.4465409475200725\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Load sentence and label data\n",
        "sentences_df = pd.read_csv('/content/drive/MyDrive/training-english/sentences.tsv', sep='\\t')\n",
        "labels_df = pd.read_csv('/content/drive/MyDrive/training-english/labels.tsv', sep='\\t')\n",
        "\n",
        "# Load precomputed BERT embeddings (assuming they are in a file like embeddings.npy or similar)\n",
        "bert_embeddings = np.load('/content/drive/MyDrive/bert_embeddings.npy')  # Change the path accordingly\n",
        "\n",
        "# Preprocessing: Merging data and selecting the dominant label\n",
        "label_columns = labels_df.columns[2:]  # Exclude 'Text-ID' and 'Sentence-ID'\n",
        "labels_df['dominant_label'] = labels_df[label_columns].idxmax(axis=1)\n",
        "# Convert dominant labels to numerical categories\n",
        "labels_df['dominant_label'] = labels_df['dominant_label'].astype('category').cat.codes\n",
        "\n",
        "# Merge text and labels data\n",
        "merged_df = sentences_df.merge(labels_df[['Text-ID', 'Sentence-ID', 'dominant_label']], on=['Text-ID', 'Sentence-ID'])\n",
        "labels = merged_df['dominant_label'].values\n",
        "\n",
        "# Split data into training and validation sets\n",
        "train_embeddings, val_embeddings, train_labels, val_labels = train_test_split(bert_embeddings, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert to torch tensors\n",
        "train_embeddings = torch.tensor(train_embeddings)\n",
        "val_embeddings = torch.tensor(val_embeddings)\n",
        "train_labels = torch.tensor(train_labels)\n",
        "val_labels = torch.tensor(val_labels)\n",
        "\n",
        "# Define the classifier (e.g., a logistic regression model)\n",
        "classifier = LogisticRegression(max_iter=1000)\n",
        "\n",
        "# Fit the classifier on the training data\n",
        "classifier.fit(train_embeddings.numpy(), train_labels.numpy())\n",
        "\n",
        "# Evaluate the classifier on the validation data\n",
        "val_preds = classifier.predict(val_embeddings.numpy())\n",
        "\n",
        "# Accuracy score\n",
        "accuracy = accuracy_score(val_labels.numpy(), val_preds)\n",
        "\n",
        "# Macro F1-score\n",
        "macro_f1 = f1_score(val_labels.numpy(), val_preds, average='macro')\n",
        "\n",
        "# Classification report for detailed performance metrics (precision, recall, f1-score, support)\n",
        "report = classification_report(val_labels.numpy(), val_preds, target_names=[str(i) for i in range(len(np.unique(labels)))], zero_division=0)\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "# print(f\"Validation Macro F1 Score: {macro_f1}\")\n",
        "print(\"Classification Report:\\n\", report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GGU8vP9teVVe",
        "outputId": "87483304-edf3-4d69-a4e6-87b0604a9abc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.5087131367292225\n",
            "Validation Macro F1 Score: 0.1503848606277319\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.32      0.16      0.21       393\n",
            "           1       0.23      0.10      0.14       143\n",
            "           2       0.22      0.10      0.14       153\n",
            "           3       0.00      0.00      0.00        14\n",
            "           4       0.20      0.10      0.14       108\n",
            "           5       0.14      0.03      0.05        32\n",
            "           6       0.12      0.03      0.04        37\n",
            "           7       0.09      0.04      0.05        55\n",
            "           8       0.31      0.22      0.26       290\n",
            "           9       0.24      0.12      0.16       155\n",
            "          10       0.05      0.01      0.02        68\n",
            "          11       0.07      0.03      0.04        80\n",
            "          12       0.27      0.17      0.21        40\n",
            "          13       0.00      0.00      0.00        19\n",
            "          14       0.00      0.00      0.00         9\n",
            "          15       0.00      0.00      0.00         5\n",
            "          16       0.20      0.17      0.19       305\n",
            "          17       0.12      0.03      0.04        75\n",
            "          18       0.29      0.19      0.23       286\n",
            "          19       0.35      0.17      0.23       150\n",
            "          20       0.30      0.10      0.15        61\n",
            "          21       0.34      0.17      0.23       111\n",
            "          22       0.36      0.23      0.28       323\n",
            "          23       0.42      0.28      0.33       409\n",
            "          24       0.25      0.07      0.10       288\n",
            "          25       0.00      0.00      0.00        55\n",
            "          26       0.59      0.87      0.70      4388\n",
            "          27       0.00      0.00      0.00        20\n",
            "          28       0.26      0.12      0.16       191\n",
            "          29       0.00      0.00      0.00        22\n",
            "          30       0.43      0.36      0.39        84\n",
            "          31       0.00      0.00      0.00        18\n",
            "          32       0.31      0.18      0.23       236\n",
            "          33       0.27      0.16      0.20       112\n",
            "          34       0.45      0.38      0.41       115\n",
            "          35       0.12      0.14      0.13        29\n",
            "          36       0.08      0.03      0.04        34\n",
            "          37       0.33      0.15      0.21        39\n",
            "\n",
            "    accuracy                           0.51      8952\n",
            "   macro avg       0.20      0.13      0.15      8952\n",
            "weighted avg       0.43      0.51      0.45      8952\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Load sentence and label data\n",
        "sentences_df = pd.read_csv('/content/drive/MyDrive/training-english/sentences.tsv', sep='\\t')\n",
        "labels_df = pd.read_csv('/content/drive/MyDrive/training-english/labels.tsv', sep='\\t')\n",
        "\n",
        "# Load precomputed BERT embeddings (assuming they are in a file like embeddings.npy or similar)\n",
        "bert_embeddings = np.load('/content/drive/MyDrive/bert_embeddings.npy')  # Change the path accordingly\n",
        "\n",
        "# Preprocessing: Merging data and selecting the dominant label\n",
        "label_columns = labels_df.columns[2:]  # Exclude 'Text-ID' and 'Sentence-ID'\n",
        "labels_df['dominant_label'] = labels_df[label_columns].idxmax(axis=1)\n",
        "# Convert dominant labels to numerical categories\n",
        "labels_df['dominant_label'] = labels_df['dominant_label'].astype('category').cat.codes\n",
        "\n",
        "# Merge text and labels data\n",
        "merged_df = sentences_df.merge(labels_df[['Text-ID', 'Sentence-ID', 'dominant_label']], on=['Text-ID', 'Sentence-ID'])\n",
        "labels = merged_df['dominant_label'].values\n",
        "\n",
        "# Split data into training and validation sets\n",
        "train_embeddings, val_embeddings, train_labels, val_labels = train_test_split(bert_embeddings, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert to torch tensors\n",
        "train_embeddings = torch.tensor(train_embeddings)\n",
        "val_embeddings = torch.tensor(val_embeddings)\n",
        "train_labels = torch.tensor(train_labels)\n",
        "val_labels = torch.tensor(val_labels)\n",
        "\n",
        "# Define the classifier (e.g., a logistic regression model)\n",
        "classifier = LogisticRegression(max_iter=1000)\n",
        "\n",
        "# Fit the classifier on the training data\n",
        "classifier.fit(train_embeddings.numpy(), train_labels.numpy())\n",
        "\n",
        "# Evaluate the classifier on the validation data\n",
        "val_preds = classifier.predict(val_embeddings.numpy())\n",
        "\n",
        "# Accuracy score\n",
        "accuracy = accuracy_score(val_labels.numpy(), val_preds)\n",
        "\n",
        "# Classification report for detailed performance metrics (precision, recall, f1-score, support)\n",
        "report = classification_report(val_labels.numpy(), val_preds, target_names=[str(i) for i in range(len(np.unique(labels)))], zero_division=0)\n",
        "\n",
        "# Extract the support values from the classification report\n",
        "support_values = report.split('\\n')[-2].split()[1:]\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(\"Support values for each class:\", support_values)\n"
      ],
      "metadata": {
        "id": "tP_btcQeaMsq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the trained BERT model\n",
        "model.save_pretrained('./transform_bert_base_uncased')\n",
        "tokenizer.save_pretrained('./transformer_bert_base_uncased')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fn6H70IUOh87",
        "outputId": "65de553b-7b6c-4274-c33b-e7fd5b58bc26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./transformer_bert_base_uncased/tokenizer_config.json',\n",
              " './transformer_bert_base_uncased/special_tokens_map.json',\n",
              " './transformer_bert_base_uncased/vocab.txt',\n",
              " './transformer_bert_base_uncased/added_tokens.json',\n",
              " './transformer_bert_base_uncased/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "from google.colab import files\n",
        "import pandas as pd\n",
        "\n",
        "# Save the model and tokenizer\n",
        "model.save_pretrained('/content/emotion_model')\n",
        "tokenizer.save_pretrained('/content/emotion_model')\n",
        "\n",
        "# Save the evaluation results\n",
        "results_df = pd.DataFrame({\n",
        "    'Accuracy': [accuracy],\n",
        "    'F1 Score': [f1]\n",
        "})\n",
        "results_df.to_csv('/content/evaluation_results.csv', index=False)\n",
        "\n",
        "# Create a zip file of the model directory\n",
        "shutil.make_archive('/content/emotion_model', 'zip', '/content', 'emotion_model')\n",
        "\n",
        "# Download the model and results\n",
        "files.download('/content/emotion_model.zip')\n",
        "files.download('/content/evaluation_results.csv')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "BWL0rpAeO7vX",
        "outputId": "919baa58-494c-4c91-b363-b392c176794d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_8734250c-d7d7-44d2-9673-de6bdcde0c37\", \"emotion_model.zip\", 406006038)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_66940330-d52a-48dd-aaad-a3793a149b75\", \"evaluation_results.csv\", 56)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "bert-base-uncased"
      ],
      "metadata": {
        "id": "H9tdc11z3ME7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers torch sklearn pandas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UmNEHsN83OXu",
        "outputId": "dd244941-940b-4359-d408-82405aae32ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.0+cu121)\n",
            "Collecting sklearn\n",
            "  Downloading sklearn-0.0.post12.tar.gz (2.6 kB)\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import BertForSequenceClassification, AdamW\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# Load data\n",
        "labels_df = pd.read_csv('/content/drive/MyDrive/training-english/labels.tsv',sep='\\t')  # Replace with your actual labels file\n",
        "sentences_df = pd.read_csv('/content/drive/MyDrive/training-english/sentences.tsv',sep='\\t')  # Replace with your actual sentences file\n",
        "\n",
        "# Merge data based on sentence-id\n",
        "merged_df = pd.merge(sentences_df, labels_df, on=\"Sentence-ID\")\n",
        "\n",
        "# Load precomputed BERT embeddings\n",
        "bert_embeddings = np.load('/content/drive/MyDrive/bert_embeddings.npy')  # Shape should be (num_sentences, embedding_dim)\n",
        "\n",
        "# Prepare multi-hot encoded labels (assuming a list of emotion labels)\n",
        "num_emotions = 20  # Adjust this as per your dataset\n",
        "labels = merged_df['labels'].apply(lambda x: list(map(int, x.split(',')))).values\n",
        "labels_multi_hot = np.zeros((len(labels), num_emotions))\n",
        "\n",
        "for i, label_list in enumerate(labels):\n",
        "    for label in label_list:\n",
        "        labels_multi_hot[i, label] = 1\n",
        "\n",
        "# Define the Dataset class\n",
        "class EmotionDataset(Dataset):\n",
        "    def __init__(self, embeddings, labels):\n",
        "        self.embeddings = embeddings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {\n",
        "            'embeddings': torch.tensor(self.embeddings[idx], dtype=torch.float),\n",
        "            'labels': torch.tensor(self.labels[idx], dtype=torch.float)\n",
        "        }\n",
        "\n",
        "# Create Dataset and DataLoader\n",
        "train_dataset = EmotionDataset(bert_embeddings, labels_multi_hot)\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "\n",
        "# Load Pre-trained BERT Model for Sequence Classification\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=num_emotions, problem_type=\"multi_label_classification\")\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "# Optimizer and Loss Function\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "loss_fn = nn.BCEWithLogitsLoss()\n",
        "\n",
        "# Training Loop\n",
        "def train_model(model, train_loader, optimizer, loss_fn, num_epochs=3):\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        for batch in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            embeddings = batch['embeddings'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(inputs_embeds=embeddings)\n",
        "            logits = outputs.logits\n",
        "\n",
        "            # Compute loss\n",
        "            loss = loss_fn(logits, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {running_loss / len(train_loader)}\")\n",
        "\n",
        "# Train the model\n",
        "train_model(model, train_loader, optimizer, loss_fn, num_epochs=3)\n",
        "\n",
        "# Evaluation Function\n",
        "def evaluate_model(model, eval_loader):\n",
        "    model.eval()\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in eval_loader:\n",
        "            embeddings = batch['embeddings'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(inputs_embeds=embeddings)\n",
        "            logits = outputs.logits\n",
        "\n",
        "            preds = (torch.sigmoid(logits) > 0.5).cpu().numpy()\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_preds.extend(preds)\n",
        "\n",
        "    f1 = f1_score(all_labels, all_preds, average='macro')\n",
        "    print(f'Macro F1 Score: {f1}')\n",
        "\n",
        "# Evaluate the model (you can create a separate eval_loader if needed)\n",
        "evaluate_model(model, train_loader)  # Or use separate validation data\n"
      ],
      "metadata": {
        "id": "zWuAiFL33sOU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Roberta model"
      ],
      "metadata": {
        "id": "dIuBb20mrtjG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from transformers import RobertaForSequenceClassification, AdamW\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "\n",
        "# Load sentence and label data\n",
        "sentences_df = pd.read_csv('/content/drive/MyDrive/training-english/sentences.tsv', sep='\\t')\n",
        "labels_df = pd.read_csv('/content/drive/MyDrive/training-english/labels.tsv', sep='\\t')\n",
        "\n",
        "# Load precomputed BERT embeddings\n",
        "bert_embeddings = np.load('/content/drive/MyDrive/bert_embeddings.npy')  # Shape: (num_sentences, embedding_dim)\n",
        "\n",
        "# Preprocessing: Merging data and selecting the dominant label\n",
        "label_columns = labels_df.columns[2:]  # Exclude 'Text-ID' and 'Sentence-ID'\n",
        "labels_df['dominant_label'] = labels_df[label_columns].idxmax(axis=1)\n",
        "# Convert dominant labels to numerical categories\n",
        "labels_df['dominant_label'] = labels_df['dominant_label'].astype('category').cat.codes\n",
        "\n",
        "# Merge text and labels data\n",
        "merged_df = sentences_df.merge(labels_df[['Text-ID', 'Sentence-ID', 'dominant_label']], on=['Text-ID', 'Sentence-ID'])\n",
        "labels = merged_df['dominant_label'].values\n",
        "\n",
        "# Split data into training and validation sets\n",
        "train_embeddings, val_embeddings, train_labels, val_labels = train_test_split(bert_embeddings, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert to torch tensors\n",
        "train_embeddings = torch.tensor(train_embeddings, dtype=torch.float)\n",
        "val_embeddings = torch.tensor(val_embeddings, dtype=torch.float)\n",
        "train_labels = torch.tensor(train_labels, dtype=torch.long)\n",
        "val_labels = torch.tensor(val_labels, dtype=torch.long)\n",
        "\n",
        "# Create DataLoader for batching\n",
        "train_dataset = TensorDataset(train_embeddings, train_labels)\n",
        "val_dataset = TensorDataset(val_embeddings, val_labels)\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
        "\n",
        "# Load Pre-trained RoBERTa Model for Sequence Classification\n",
        "model = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=len(np.unique(labels)))\n",
        "device = torch.device('cpu')  # Using CPU only\n",
        "model.to(device)\n",
        "\n",
        "# Optimizer\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "\n",
        "# Training Loop\n",
        "def train_model(model, train_loader, optimizer, num_epochs=3):\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        for embeddings, labels in train_loader:\n",
        "            embeddings, labels = embeddings.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs_embeds=embeddings)\n",
        "            loss = outputs.loss\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {running_loss / len(train_loader)}\")\n",
        "\n",
        "# Train the model\n",
        "train_model(model, train_loader, optimizer, num_epochs=3)\n",
        "\n",
        "# Evaluation Function\n",
        "def evaluate_model(model, val_loader):\n",
        "    model.eval()\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for embeddings, labels in val_loader:\n",
        "            embeddings = embeddings.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs_embeds=embeddings)\n",
        "            logits = outputs.logits\n",
        "            preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
        "\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_preds.extend(preds)\n",
        "\n",
        "    # Compute metrics\n",
        "    accuracy = accuracy_score(all_labels, all_preds)\n",
        "    weighted_f1 = f1_score(all_labels, all_preds, average='weighted')\n",
        "    report = classification_report(all_labels, all_preds, target_names=[str(i) for i in range(len(np.unique(labels)))], zero_division=0)\n",
        "\n",
        "    print(f\"Accuracy: {accuracy}\")\n",
        "    print(f\"Weighted F1 Score: {weighted_f1}\")\n",
        "    print(\"Classification Report:\\n\", report)\n",
        "\n",
        "# Evaluate the model\n",
        "evaluate_model(model, val_loader)\n"
      ],
      "metadata": {
        "id": "B2_RfVrkrs2V"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}